{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<font size=\"6\">**Task 1: data mining**</font>\n",
    "\n",
    "**1.1 Get pokemon data from pokeAPI**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 定义保存图片的目录\n",
    "save_directory = \"data/pokemon_images\"\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# 获取所有宝可梦的基本信息\n",
    "url = \"https://pokeapi.co/api/v2/pokemon?limit=10000\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# 创建一个字典来存储宝可梦的名称和属性\n",
    "pokemon_info = {}\n",
    "\n",
    "# 遍历每个宝可梦\n",
    "for pokemon in data['results']:\n",
    "    pokemon_name = pokemon['name']\n",
    "    pokemon_url = pokemon['url']\n",
    "    response = requests.get(pokemon_url)\n",
    "    pokemon_data = response.json()\n",
    "\n",
    "    # 获取宝可梦的属性\n",
    "    types = pokemon_data['types']\n",
    "    type_names = [type_info['type']['name'] for type_info in types]\n",
    "\n",
    "    # 获取宝可梦的图片链接\n",
    "    pic1_url = pokemon_data['sprites']['other']['official-artwork']['front_default']\n",
    "    pic2_url = pokemon_data['sprites']['other']['home']['front_default']\n",
    "    pic3_url = pokemon_data['sprites']['front_default']\n",
    "\n",
    "    # 下载并保存图片\n",
    "    for i, pic_url in enumerate([pic1_url, pic2_url, pic3_url], start=1):\n",
    "        if pic_url:\n",
    "            img_response = requests.get(pic_url)\n",
    "            if img_response.status_code == 200:\n",
    "                img_name = f\"{pokemon_name}_pic{i}.png\"\n",
    "                img_path = os.path.join(save_directory, img_name)\n",
    "                with open(img_path, 'wb') as file:\n",
    "                    file.write(img_response.content)\n",
    "\n",
    "    # 将宝可梦的名称和属性存储到字典中\n",
    "    pokemon_info[pokemon_name] = {\n",
    "        \"types\": type_names,\n",
    "        \"images\": [os.path.join(save_directory, f\"{pokemon_name}_pic{i}.png\") for i in range(1, 4) if eval(f\"pic{i}_url\")]\n",
    "    }\n",
    "\n",
    "# 将字典转换为 JSON 格式并保存到文件中\n",
    "with open('data/pokemon_info.json', 'w') as json_file:\n",
    "    json.dump(pokemon_info, json_file, indent=4)\n",
    "\n",
    "print(f\"所有宝可梦的名称和属性已保存到 pokemon_info.json 文件中，图片保存在 {save_directory} 目录中。\")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-07T08:33:30.775191Z",
     "iopub.execute_input": "2024-12-07T08:33:30.775637Z",
     "iopub.status.idle": "2024-12-07T08:45:52.057371Z",
     "shell.execute_reply.started": "2024-12-07T08:33:30.775598Z",
     "shell.execute_reply": "2024-12-07T08:45:52.056120Z"
    },
    "ExecuteTime": {
     "end_time": "2024-12-07T11:10:54.846644Z",
     "start_time": "2024-12-07T10:28:55.014281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有宝可梦的名称和属性已保存到 pokemon_info.json 文件中，图片保存在 data/pokemon_images 目录中。\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<font size=\"6\">**Task 2: Training of pokemon type**</font>"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**2.1 Preprocessing**"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T07:22:46.406457Z",
     "start_time": "2024-12-13T07:22:46.395131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "\n",
    "# 定义自定义数据集类\n",
    "class PokemonDataset(Dataset):\n",
    "    def __init__(self, data_dict, transform=None):\n",
    "        self.data_dict = data_dict\n",
    "        self.transform = transform\n",
    "        self.image_files = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # 遍历数据字典，获取所有图像文件路径和对应的标签（属性）\n",
    "        for pokemon_name, info in data_dict.items():\n",
    "            for img_path in info['images']:\n",
    "                self.image_files.append(img_path)\n",
    "                self.labels.append(info['types'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # 获取宝可梦的标签（属性）\n",
    "        labels = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # 将字符串标签转换为整数标签\n",
    "        label_map = {'grass': 0, 'poison': 1, 'fire': 2, 'water': 3, 'electric': 4, 'ice': 5, 'fighting': 6,\n",
    "                     'ground': 7, 'flying': 8, 'psychic': 9, 'bug': 10, 'rock': 11, 'ghost': 12, 'dark': 13,\n",
    "                     'dragon': 14, 'steel': 15, 'fairy': 16, 'normal': 17}\n",
    "        labels = [label_map[label] for label in labels]\n",
    "        \n",
    "        # 将标签转换为多标签二进制格式\n",
    "        multi_label = torch.zeros(len(label_map), dtype=torch.float32)\n",
    "        for label in labels:\n",
    "            multi_label[label] = 1.0\n",
    "        \n",
    "        return image, multi_label\n",
    "\n",
    "# 读取数据字典\n",
    "with open('data/pokemon_info.json', 'r') as f:\n",
    "    data_dict = json.load(f)\n",
    "\n",
    "# 定义训练数据的转换\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 创建数据集\n",
    "pokemon_dataset = PokemonDataset(data_dict=data_dict, transform=data_transforms)\n",
    "\n",
    "# 将数据集分割为训练集、验证集和测试集（80%、10%、10%）\n",
    "train_size = int(0.8 * len(pokemon_dataset))\n",
    "val_size = int(0.1 * len(pokemon_dataset))\n",
    "test_size = len(pokemon_dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(pokemon_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**2.2 Model and training**"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T07:32:01.469290Z",
     "start_time": "2024-12-13T07:24:02.166505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 定义自定义数据集类\n",
    "class PokemonDataset(Dataset):\n",
    "    def __init__(self, data_dict, transform=None):\n",
    "        self.data_dict = data_dict\n",
    "        self.transform = transform\n",
    "        self.image_files = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # 遍历数据字典，获取所有图像文件路径和对应的标签（属性）\n",
    "        for pokemon_name, info in data_dict.items():\n",
    "            for img_path in info['images']:\n",
    "                self.image_files.append(img_path)\n",
    "                self.labels.append(info['types'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        \n",
    "        # 使用OpenCV加载图像\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            print(f\"UnidentifiedImageError: cannot identify image file '{img_path}'\")\n",
    "            return self.__getitem__((idx + 1) % len(self.image_files))\n",
    "        \n",
    "        # 将图像从BGR转换为RGB\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 获取宝可梦的标签（属性）\n",
    "        labels = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # 将字符串标签转换为整数标签\n",
    "        label_map = {'grass': 0, 'poison': 1, 'fire': 2, 'water': 3, 'electric': 4, 'ice': 5, 'fighting': 6,\n",
    "                     'ground': 7, 'flying': 8, 'psychic': 9, 'bug': 10, 'rock': 11, 'ghost': 12, 'dark': 13,\n",
    "                     'dragon': 14, 'steel': 15, 'fairy': 16, 'normal': 17}\n",
    "        labels = [label_map[label] for label in labels]\n",
    "        \n",
    "        # 将标签转换为多标签二进制格式\n",
    "        multi_label = torch.zeros(len(label_map), dtype=torch.float32)\n",
    "        for label in labels:\n",
    "            multi_label[label] = 1.0\n",
    "        \n",
    "        return image, multi_label\n",
    "\n",
    "# 定义函数来提取图像特征\n",
    "def extract_features(model, dataloader):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            features.append(outputs.cpu().numpy())\n",
    "    return np.concatenate(features)\n",
    "\n",
    "\n",
    "# 读取数据字典\n",
    "with open('data/pokemon_info.json', 'r') as f:\n",
    "    data_dict = json.load(f)\n",
    "\n",
    "# 定义训练数据的转换\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 创建数据集\n",
    "pokemon_dataset = PokemonDataset(data_dict=data_dict, transform=data_transforms)\n",
    "\n",
    "# 将数据集分割为训练集、验证集和测试集（80%、10%、10%）\n",
    "train_size = int(0.8 * len(pokemon_dataset))\n",
    "val_size = int(0.1 * len(pokemon_dataset))\n",
    "test_size = len(pokemon_dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(pokemon_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# 检查是否有可用的GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 加载预训练的ResNet18模型\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# 修改最后一层以匹配属性的数量（假设有18种可能的属性）\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 18)\n",
    "\n",
    "# 将模型移动到GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# 训练循环\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs_labels in train_loader:\n",
    "        if inputs_labels is None:\n",
    "            continue\n",
    "        \n",
    "        inputs, labels = inputs_labels\n",
    "        \n",
    "        # 将输入和标签移动到GPU\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # 验证循环\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs_labels in val_loader:\n",
    "            if inputs_labels is None:\n",
    "                continue\n",
    "            \n",
    "            inputs, labels = inputs_labels\n",
    "            \n",
    "            # 将输入和标签移动到GPU\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    print(f\"Validation Loss: {val_loss/len(val_loader)}\")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# 测试循环（可选）\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for inputs_labels in test_loader:\n",
    "        if inputs_labels is None:\n",
    "            continue\n",
    "        \n",
    "        inputs, labels = inputs_labels\n",
    "        \n",
    "        # 将输入和标签移动到GPU\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "print(f\"Test Loss: {test_loss/len(test_loader)}\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Epoch 1/20, Loss: 0.3015347325624271\n",
      "Validation Loss: 0.28118698222121014\n",
      "Epoch 2/20, Loss: 0.2769729947487925\n",
      "Validation Loss: 0.26360021900270403\n",
      "Epoch 3/20, Loss: 0.2636679448959432\n",
      "Validation Loss: 0.2527120541205111\n",
      "Epoch 4/20, Loss: 0.25308770371765055\n",
      "Validation Loss: 0.2441973531829942\n",
      "Epoch 5/20, Loss: 0.24287912857578825\n",
      "Validation Loss: 0.2363066161723481\n",
      "Epoch 6/20, Loss: 0.23445101987589825\n",
      "Validation Loss: 0.2303259541693422\n",
      "Epoch 7/20, Loss: 0.22668955533963103\n",
      "Validation Loss: 0.22565625984336912\n",
      "Epoch 8/20, Loss: 0.21940744281239768\n",
      "Validation Loss: 0.2215224751799377\n",
      "Epoch 9/20, Loss: 0.20787746508465837\n",
      "Validation Loss: 0.21708014538300405\n",
      "Epoch 10/20, Loss: 0.19980790511429927\n",
      "Validation Loss: 0.2146109573005401\n",
      "Epoch 11/20, Loss: 0.19193015428057297\n",
      "Validation Loss: 0.21295362611099616\n",
      "Epoch 12/20, Loss: 0.1812104575741322\n",
      "Validation Loss: 0.21135934019826122\n",
      "Epoch 13/20, Loss: 0.17058763386672024\n",
      "Validation Loss: 0.20369247996161893\n",
      "Epoch 14/20, Loss: 0.16265154782431732\n",
      "Validation Loss: 0.20995871907042474\n",
      "Epoch 15/20, Loss: 0.15261471620881495\n",
      "Validation Loss: 0.2030828278703788\n",
      "Epoch 16/20, Loss: 0.1417701702873787\n",
      "Validation Loss: 0.2014562721104966\n",
      "Epoch 17/20, Loss: 0.1321228461513788\n",
      "Validation Loss: 0.20103522678165092\n",
      "Epoch 18/20, Loss: 0.12329844008513528\n",
      "Validation Loss: 0.20027692888661758\n",
      "Epoch 19/20, Loss: 0.11275986282376892\n",
      "Validation Loss: 0.19677516879494658\n",
      "Epoch 20/20, Loss: 0.10482501660816256\n",
      "Validation Loss: 0.20139268113626646\n",
      "Training complete.\n",
      "Test Loss: 0.20307834438749195\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<font size=\"6\">**Task 3: Analysis of types from other games**</font>"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<font size=\"6\">**Task 4: Most similar pokemon**</font>"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**4.1 Different functions of calculation of similarity**\n",
    "\n",
    "4.1.1 cosine_similarity"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T07:32:33.714860Z",
     "start_time": "2024-12-13T07:32:13.356225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 示例：查找与查询图像最相似的三个宝可梦图像\n",
    "# 定义函数来找到最相似的宝可梦图像\n",
    "def find_similar_images(query_image_path, model, feature_extractor, dataset, dataloader, top_k=3):\n",
    "    # 加载查询图像并进行预处理\n",
    "    query_image = cv2.imread(query_image_path)\n",
    "    if query_image is None:\n",
    "        raise ValueError(f\"Cannot identify image file '{query_image_path}'\")\n",
    "    \n",
    "    query_image = cv2.cvtColor(query_image, cv2.COLOR_BGR2RGB)\n",
    "    query_image = data_transforms(query_image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # 提取查询图像的特征\n",
    "    with torch.no_grad():\n",
    "        query_features = feature_extractor(query_image).cpu().numpy()\n",
    "    \n",
    "    # 提取数据集中所有图像的特征\n",
    "    dataset_features = extract_features(feature_extractor, dataloader)\n",
    "    \n",
    "    # 计算余弦相似度\n",
    "    similarities = cosine_similarity(query_features, dataset_features)\n",
    "    \n",
    "    # 找到最相似的图像索引\n",
    "    top_k_indices = np.argsort(similarities[0])[::-1][:top_k]\n",
    "    \n",
    "    # 返回最相似的图像路径和相似度分数\n",
    "    similar_images = [(dataset.image_files[idx], similarities[0][idx]) for idx in top_k_indices]\n",
    "    \n",
    "    return similar_images\n",
    "\n",
    "query_image_path = 'data/palworld_images/Anubis.png'\n",
    "similar_images = find_similar_images(query_image_path, model, model, pokemon_dataset, train_loader, top_k=3)\n",
    "print(\"Most similar images:\")\n",
    "for img_path, score in similar_images:\n",
    "    print(f\"Image: {img_path}, Similarity Score: {score}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar images:\n",
      "Image: data/pokemon_images\\omanyte_pic1.png, Similarity Score: 0.9607487916946411\n",
      "Image: data/pokemon_images\\roserade_pic2.png, Similarity Score: 0.9476977586746216\n",
      "Image: data/pokemon_images\\fraxure_pic1.png, Similarity Score: 0.9373520612716675\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4.1.2 Euclidean"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T07:44:03.856273Z",
     "start_time": "2024-12-13T07:43:44.288476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def find_similar_images_euclidean(query_image_path, model, feature_extractor, dataset, dataloader, top_k=3):\n",
    "    query_image = cv2.imread(query_image_path)\n",
    "    if query_image is None:\n",
    "        raise ValueError(f\"Cannot identify image file '{query_image_path}'\")\n",
    "\n",
    "    query_image = cv2.cvtColor(query_image, cv2.COLOR_BGR2RGB)\n",
    "    query_image = data_transforms(query_image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        query_features = feature_extractor(query_image).cpu().numpy()\n",
    "\n",
    "    dataset_features = extract_features(feature_extractor, dataloader)\n",
    "\n",
    "    distances = euclidean_distances(query_features, dataset_features)\n",
    "\n",
    "    top_k_indices = np.argsort(distances[0])[:top_k]\n",
    "\n",
    "    similar_images = [(dataset.image_files[idx], distances[0][idx]) for idx in top_k_indices]\n",
    "\n",
    "    return similar_images\n",
    "\n",
    "query_image_path = 'data/palworld_images/Anubis.png'\n",
    "similar_images = find_similar_images_euclidean(query_image_path, model, model, pokemon_dataset, train_loader, top_k=3)\n",
    "print(\"Most similar images:\")\n",
    "for img_path, score in similar_images:\n",
    "    print(f\"Image: {img_path}, Distance: {score}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar images:\n",
      "Image: data/pokemon_images\\nidoqueen_pic2.png, Distance: 9.441254615783691\n",
      "Image: data/pokemon_images\\toxapex_pic2.png, Distance: 9.872849464416504\n",
      "Image: data/pokemon_images\\kirlia_pic3.png, Distance: 10.014799118041992\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4.1.3 VGG"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T07:34:34.591012Z",
     "start_time": "2024-12-13T07:34:10.233796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.models import vgg16\n",
    "\n",
    "# 加载预训练的VGG16模型\n",
    "vgg_model = vgg16(pretrained=True)\n",
    "vgg_model.classifier = nn.Sequential(*list(vgg_model.classifier.children())[:-1])  # 移除最后一层\n",
    "vgg_model = vgg_model.to(device)\n",
    "\n",
    "def extract_vgg_features(model, dataloader):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            features.append(outputs.cpu().numpy())\n",
    "    return np.concatenate(features)\n",
    "\n",
    "query_image_path = 'data/palworld_images/Anubis.png'\n",
    "similar_images = find_similar_images(query_image_path, vgg_model, vgg_model, pokemon_dataset, train_loader, top_k=3)\n",
    "print(\"Most similar images:\")\n",
    "for img_path, score in similar_images:\n",
    "    print(f\"Image: {img_path}, Similarity Score: {score}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\业\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\业\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar images:\n",
      "Image: data/pokemon_images\\inkay_pic3.png, Similarity Score: 0.46852004528045654\n",
      "Image: data/pokemon_images\\simipour_pic1.png, Similarity Score: 0.4677070379257202\n",
      "Image: data/pokemon_images\\koraidon_pic2.png, Similarity Score: 0.45726901292800903\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4.1.4 Hashes"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T07:35:15.985748Z",
     "start_time": "2024-12-13T07:35:06.936753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import imagehash\n",
    "import numpy as np\n",
    " \n",
    "def find_similar_images_hash(query_image_path, dataset, top_k=3):\n",
    "    # 使用 OpenCV 读取图像\n",
    "    query_image = cv2.imread(query_image_path)\n",
    "    # OpenCV 读取的图像是 BGR 格式，需要转换为 RGB 格式\n",
    "    query_image_rgb = cv2.cvtColor(query_image, cv2.COLOR_BGR2RGB)\n",
    "    # 将图像转换为 Pillow 图像对象以使用 imagehash 库\n",
    "    query_image_pil = Image.fromarray(query_image_rgb)\n",
    "    query_hash = imagehash.phash(query_image_pil)\n",
    " \n",
    "    image_hashes = []\n",
    "    for img_path in dataset.image_files:\n",
    "        # 使用 OpenCV 读取图像\n",
    "        img = cv2.imread(img_path)\n",
    "        # 转换为 RGB 格式\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # 转换为 Pillow 图像对象\n",
    "        img_pil = Image.fromarray(img_rgb)\n",
    "        # 计算图像哈希\n",
    "        img_hash = imagehash.phash(img_pil)\n",
    "        image_hashes.append((img_path, img_hash))\n",
    " \n",
    "    similarities = [(img_path, 1 - (query_hash - img_hash) / len(query_hash.hash)**2) for img_path, img_hash in image_hashes]\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    " \n",
    "    return similarities[:top_k]\n",
    " \n",
    "query_image_path = 'data/palworld_images/Anubis.png'\n",
    "# 假设 pokemon_dataset 是一个具有 image_files 属性的对象，该属性包含图像文件路径的列表\n",
    "# 注意：你需要确保 pokemon_dataset 已经被正确定义并包含有效的图像文件路径\n",
    "similar_images = find_similar_images_hash(query_image_path, pokemon_dataset, top_k=3)\n",
    "print(\"Most similar images:\")\n",
    "for img_path, score in similar_images:\n",
    "    print(f\"Image: {img_path}, Similarity Score: {score}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar images:\n",
      "Image: data/pokemon_images\\pichu_pic3.png, Similarity Score: 0.75\n",
      "Image: data/pokemon_images\\chinchou_pic3.png, Similarity Score: 0.71875\n",
      "Image: data/pokemon_images\\porygon2_pic2.png, Similarity Score: 0.71875\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4.1.5 Combined"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T07:56:15.032906Z",
     "start_time": "2024-12-13T07:55:46.382288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "\n",
    "def find_similar_images_combined(query_image_path, model, feature_extractor, dataset, dataloader, top_k=3):\n",
    "    # 加载查询图像并进行预处理\n",
    "    query_image = cv2.imread(query_image_path)\n",
    "    if query_image is None:\n",
    "        raise ValueError(f\"Cannot identify image file '{query_image_path}'\")\n",
    "    query_image = cv2.cvtColor(query_image, cv2.COLOR_BGR2RGB)\n",
    "    query_image_tensor = data_transforms(query_image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # 提取查询图像的特征\n",
    "    with torch.no_grad():\n",
    "        query_features = feature_extractor(query_image_tensor).cpu().numpy()\n",
    "    \n",
    "    # 提取数据集中所有图像的特征\n",
    "    dataset_features = extract_features(feature_extractor, dataloader)\n",
    "    \n",
    "    # 计算余弦相似度\n",
    "    cosine_similarities = cosine_similarity(query_features, dataset_features)\n",
    "    \n",
    "    # 计算哈希相似度\n",
    "    query_image_pil = Image.fromarray(query_image)\n",
    "    query_hash = imagehash.phash(query_image_pil)\n",
    "    image_hashes = []\n",
    "    for img_path in dataset.image_files:\n",
    "        img = cv2.imread(img_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_pil = Image.fromarray(img_rgb)\n",
    "        img_hash = imagehash.phash(img_pil)\n",
    "        image_hashes.append((img_path, img_hash))\n",
    "    \n",
    "    # 计算哈希相似度的归一化分数（这里使用汉明距离的平方的倒数进行归一化）\n",
    "    # 注意：由于phash产生的是64位的哈希值，因此最大可能的汉明距离是64\n",
    "    max_hamming_distance = 64\n",
    "    hash_similarities = []\n",
    "    for img_path, img_hash in image_hashes:\n",
    "        hamming_distance = query_hash - img_hash  # imagehash库支持直接相减得到汉明距离\n",
    "        normalized_hash_similarity = 1 - (hamming_distance / max_hamming_distance)  # 归一化到[0, 1]\n",
    "        hash_similarities.append((img_path, normalized_hash_similarity))\n",
    "    \n",
    "    # 创建一个字典来存储所有图像的路径和它们的加权相似度分数\n",
    "    final_scores = {}\n",
    "    for i, (img_path_cosine, cosine_score) in enumerate(zip(dataset.image_files, cosine_similarities[0])):\n",
    "        # 由于hash_similarities也是按照dataset.image_files的顺序，因此可以直接用i索引\n",
    "        img_path_hash, hash_score = hash_similarities[i]\n",
    "        # 确保两者对应的是同一张图像（理论上应该是，但为了安全起见还是检查一下）\n",
    "        assert img_path_cosine == img_path_hash, \"Image paths mismatch between cosine and hash similarities\"\n",
    "        # 计算加权相似度分数\n",
    "        final_score = 0.8 * cosine_score + 0.2 * hash_score\n",
    "        final_scores[img_path_cosine] = final_score\n",
    "    \n",
    "    # 根据最终相似度分数排序，返回前三名\n",
    "    sorted_final_scores = sorted(final_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_final_scores[:top_k]\n",
    "\n",
    "query_image_path = 'data/palworld_images/Anubis.png'\n",
    "# 假设 pokemon_dataset 是一个具有 image_files 属性的对象，该属性包含图像文件路径的列表\n",
    "# 注意：你需要确保 pokemon_dataset 已经被正确定义并包含有效的图像文件路径\n",
    "similar_images = find_similar_images_combined(query_image_path, model, model, pokemon_dataset, train_loader, top_k=3)\n",
    "print(\"Most similar images:\")\n",
    "for img_path, score in similar_images:\n",
    "    print(f\"Image: {img_path}, Similarity Score: {score}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar images:\n",
      "Image: data/pokemon_images\\whirlipede_pic3.png, Similarity Score: 0.8699132442474367\n",
      "Image: data/pokemon_images\\rellor_pic3.png, Similarity Score: 0.8518013000488283\n",
      "Image: data/pokemon_images\\caterpie_pic3.png, Similarity Score: 0.8471257209777833\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**4.2  Try to use unet model**"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T06:45:24.481033Z",
     "start_time": "2024-12-13T06:45:23.008893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(n_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, n_classes, kernel_size=3, padding=1),\n",
    "        )\n",
    "        \n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # 全局平均池化\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc = self.encoder(x)\n",
    "        mid = self.middle(enc)\n",
    "        dec = self.decoder(mid)\n",
    "        out = self.global_avg_pool(dec)  # 形状变为 [batch_size, n_classes, 1, 1]\n",
    "        return out.view(out.size(0), -1)  # 形状变为 [batch_size, n_classes]\n",
    "\n",
    "\n",
    "# 初始化 UNet 模型\n",
    "n_channels = 3  # 输入图像通道数（RGB 图像）\n",
    "n_classes = 18  # 输出类别数（多标签分类）\n",
    "model_u = UNet(n_channels, n_classes)\n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model_u = model_u.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.BCEWithLogitsLoss()  # 多标签分类任务的损失函数\n",
    "optimizer = optim.Adam(model_u.parameters(), lr=0.001)  # 使用 Adam 优化器"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T07:15:11.090378Z",
     "start_time": "2024-12-13T06:54:45.869318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image, ImageFile, UnidentifiedImageError\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "num_epochs = 40\n",
    "for epoch in range(num_epochs):\n",
    "    model_u.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs_labels in train_loader:\n",
    "        if inputs_labels is None:\n",
    "            continue\n",
    "        \n",
    "        inputs, labels = inputs_labels\n",
    "        \n",
    "        # 将输入和标签移动到 GPU\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_u(inputs)\n",
    "\n",
    "        # 将输出调整为与标签形状一致\n",
    "        outputs = outputs.view(outputs.size(0), -1)\n",
    "        labels = labels.view(labels.size(0), -1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # 验证循环\n",
    "    model_u.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs_labels in val_loader:\n",
    "            if inputs_labels is None:\n",
    "                continue\n",
    "\n",
    "            inputs, labels = inputs_labels\n",
    "\n",
    "            # 将输入和标签移动到 GPU\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model_u(inputs)\n",
    "\n",
    "            # 将输出调整为与标签形状一致\n",
    "            outputs = outputs.view(outputs.size(0), -1)\n",
    "            labels = labels.view(labels.size(0), -1)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss/len(val_loader)}\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Loss: 0.29572675599103765\n",
      "Validation Loss: 0.2938861498205932\n",
      "Epoch 2/40, Loss: 0.29342376415670846\n",
      "Validation Loss: 0.29187320940887806\n",
      "Epoch 3/40, Loss: 0.29265110920439114\n",
      "Validation Loss: 0.29155574892599556\n",
      "Epoch 4/40, Loss: 0.29261692968520475\n",
      "Validation Loss: 0.2922781739652771\n",
      "Epoch 5/40, Loss: 0.29270499404230266\n",
      "Validation Loss: 0.29135680367651673\n",
      "Epoch 6/40, Loss: 0.2923475724350603\n",
      "Validation Loss: 0.29023011382093133\n",
      "Epoch 7/40, Loss: 0.29211469066034945\n",
      "Validation Loss: 0.2907717083532786\n",
      "Epoch 8/40, Loss: 0.29219488403880534\n",
      "Validation Loss: 0.2894417121238315\n",
      "Epoch 9/40, Loss: 0.2914232803711311\n",
      "Validation Loss: 0.28792982202829775\n",
      "Epoch 10/40, Loss: 0.2907567130006039\n",
      "Validation Loss: 0.288155108075781\n",
      "Epoch 11/40, Loss: 0.29009782461150324\n",
      "Validation Loss: 0.28611178988033964\n",
      "Epoch 12/40, Loss: 0.2889221167201514\n",
      "Validation Loss: 0.28576364544863553\n",
      "Epoch 13/40, Loss: 0.2884591786586559\n",
      "Validation Loss: 0.28445007982327764\n",
      "Epoch 14/40, Loss: 0.28732194460040544\n",
      "Validation Loss: 0.2861774159768193\n",
      "Epoch 15/40, Loss: 0.283882427786916\n",
      "Validation Loss: 0.27732104877221214\n",
      "Epoch 16/40, Loss: 0.2804991721605081\n",
      "Validation Loss: 0.27545302461103066\n",
      "Epoch 17/40, Loss: 0.2787053816869778\n",
      "Validation Loss: 0.27402479639372873\n",
      "Epoch 18/40, Loss: 0.27680726515351184\n",
      "Validation Loss: 0.27512961195916247\n",
      "Epoch 19/40, Loss: 0.27419393656321756\n",
      "Validation Loss: 0.27308470978564825\n",
      "Epoch 20/40, Loss: 0.2726688857909311\n",
      "Validation Loss: 0.26846485131794645\n",
      "Epoch 21/40, Loss: 0.2709844179953318\n",
      "Validation Loss: 0.2693520764407423\n",
      "Epoch 22/40, Loss: 0.27032382710030967\n",
      "Validation Loss: 0.2691262410473578\n",
      "Epoch 23/40, Loss: 0.2702601843470119\n",
      "Validation Loss: 0.26870004417970006\n",
      "Epoch 24/40, Loss: 0.26826268652637386\n",
      "Validation Loss: 0.26888986392733977\n",
      "Epoch 25/40, Loss: 0.26755428152071997\n",
      "Validation Loss: 0.26570360669770193\n",
      "Epoch 26/40, Loss: 0.26572950149601604\n",
      "Validation Loss: 0.2611859419296697\n",
      "Epoch 27/40, Loss: 0.26309181560660894\n",
      "Validation Loss: 0.26295947367997513\n",
      "Epoch 28/40, Loss: 0.2621617164617221\n",
      "Validation Loss: 0.26195521913852887\n",
      "Epoch 29/40, Loss: 0.2595774527697057\n",
      "Validation Loss: 0.25888233363013907\n",
      "Epoch 30/40, Loss: 0.2572686614594157\n",
      "Validation Loss: 0.26639750123638467\n",
      "Epoch 31/40, Loss: 0.25580839440226555\n",
      "Validation Loss: 0.25594190285377894\n",
      "Epoch 32/40, Loss: 0.25426877205081555\n",
      "Validation Loss: 0.2578146913924168\n",
      "Epoch 33/40, Loss: 0.25185738091834775\n",
      "Validation Loss: 0.25639392312654513\n",
      "Epoch 34/40, Loss: 0.25049485629086665\n",
      "Validation Loss: 0.2575528758395578\n",
      "Epoch 35/40, Loss: 0.24952182056951708\n",
      "Validation Loss: 0.2522827737110177\n",
      "Epoch 36/40, Loss: 0.24739120005982218\n",
      "Validation Loss: 0.24944299152216962\n",
      "Epoch 37/40, Loss: 0.24413987735546933\n",
      "Validation Loss: 0.25365609621878754\n",
      "Epoch 38/40, Loss: 0.241841937149899\n",
      "Validation Loss: 0.2507902188706644\n",
      "Epoch 39/40, Loss: 0.23985760171603354\n",
      "Validation Loss: 0.25038478039589124\n",
      "Epoch 40/40, Loss: 0.23645372899162337\n",
      "Validation Loss: 0.2546477270187791\n",
      "Training complete.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T07:57:40.508089Z",
     "start_time": "2024-12-13T07:57:13.893736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_image_path = 'data/palworld_images/Anubis.png'\n",
    "# 假设 pokemon_dataset 是一个具有 image_files 属性的对象，该属性包含图像文件路径的列表\n",
    "# 注意：你需要确保 pokemon_dataset 已经被正确定义并包含有效的图像文件路径\n",
    "similar_images = find_similar_images_combined(query_image_path, model_u, model_u, pokemon_dataset, train_loader, top_k=3)\n",
    "print(\"Most similar images:\")\n",
    "for img_path, score in similar_images:\n",
    "    print(f\"Image: {img_path}, Similarity Score: {score}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar images:\n",
      "Image: data/pokemon_images\\tsareena_pic1.png, Similarity Score: 0.7474530220031739\n",
      "Image: data/pokemon_images\\meditite_pic1.png, Similarity Score: 0.7121516704559326\n",
      "Image: data/pokemon_images\\croconaw_pic3.png, Similarity Score: 0.7039288520812989\n"
     ]
    }
   ],
   "execution_count": 43
  }
 ]
}
